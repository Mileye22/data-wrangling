{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7827b09d",
   "metadata": {},
   "source": [
    "Wrangling data is one aspect of data analysis that a data analyst must be good at in order to produce a clean and effective data for analysis. Although it comes with its challenges, Most real life data needs to be wrangled before you can present it for EDA. While this data i worked on is not an exception because it's a real life data. I faced many problems before getting the master dataset. All the challenges faced can basically be summarized into 3:\n",
    "1. getting the data.\n",
    "2. Assesing the dataset. \n",
    "3. Cleaning issues.\n",
    "\n",
    "Getting the Data - Gathering the 3 datasets that was supposed to be used for this project wasn't easy. Although the first dataset was a downloadable file which is just to be read using pd.read_csv command. The other two were not the same. I had to make use of the requests library to pull the data from its source. write its content to a file and then load the dataset using the same pd.read_csv for the second dataset (since its a tsv text file), while the last dataset content was a json file which needs to be unloaded using the json.loads command and the needed variables are taken out from its content based on its rows and loaded into a pandas dataframe.\n",
    "\n",
    "Assessing the dataset- The method I employed in assessing the data was both visual and programmatic assessing.The documents were opened in excel to check for both quality and structural issues while some code was also run to check for additional issues. The following were the observation made during the process : \n",
    "\n",
    "__Quality issue__\n",
    "- Tweet_id not a string in twitter_archive and image_description..\n",
    "- Erroneous data_type in twitter_archive(i.e timestamp, in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id,   retweeted_status_user_id, retweeted_status_timestamp).\n",
    "\n",
    "- Retweet instead of Tweet in some columns(i.e in rows where retweet_id is not null)\n",
    "\n",
    "- inconsistent rating denominator (i.e some rating denominator > 10, while some < 10)\n",
    "\n",
    "- Tweet about others things instead of dogs in some rows (i.e @ id= 49, 61, 64, 156, 1033, 1099, 1251, 1261, 1780, 1879)\n",
    "\n",
    "- Missing values in some columns\n",
    "\n",
    "- Some Tweets has no rating in its text ( i.e @ id = 342, 516 )\n",
    "\n",
    "- Non descriptive column names in image_description table.\n",
    "\n",
    "- inconsistent entries in p1,p2, p3 columns sometimes lower case, upper case and also dashes in between words.\n",
    "\n",
    "__Tidiness issues__\n",
    "- text column contains more than 1 variable in archive_table.\n",
    "\n",
    "- 1 variable in 4 columns in tweeter_archive table\n",
    "\n",
    "- Twitter_additional should be part of tweeter_archive\n",
    "\n",
    "\n",
    "Cleaning the dataset - While cleaning to get rid of the issues listed in the assess section.I dropped rows irrelevant to the studies, filled incorrect entries in some rows, dropped columns which were not necessary, reshape some columns to fit to the requirements for tidiness and quality data.\n",
    "\n",
    "I also observed some more data issues not observed earlier like having just a single character in the name columns.\n",
    "\n",
    "This observations made me realize how being a Data detective can be a tool for every data analyst in making us have a good and efficient dataset for EDA. And also its process is iterative.\n",
    "\n",
    "In conclusion, from the 3 datasets given I ended up with 2 master dataset after the process of wrangling to meet the conditions of tidiness and also quality\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5916bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
